Vale, hola, hola sí, hola a todos. Me voy a autograbar, pero ya ya veréis por qué. Ahora ya lo entenderéis.
Eh, bueno, estamos en en la clase de aprendizaje bioestadístico. La clase de hoy va a ser un poquito formal. Ah, informal, perdón. En el sentido de que de que aunque tenía por ahí un notebook de unas clases que di hace como un año, pero le cambié algunas cosas.
Pero antes que que nada, eh, antes que nada, eh, os recomiendo que vayáis a esta a esta página, a cursor.com o cursor.sh. Vale.
Eh, aquí, este es un, ese es, hay hay dos digamos IDEs famosos hoy en día. Los dos se basan en Visual Studio Code. El mismo Visual Studio Code también tiene Copilot. Eh, pero estos dos son mejores. Entonces, Cursor es uno y Winsurf es otro. Eh, que es que es esta esta página, ¿vale? Yo yo los tengo los dos. Los suelo usar de forma intercambiable, porque uno me parece mejor que que otro.
48 48 48. Tres veces.
Eh, vale. Voy a basarme más en en Cursor, me gusta un poco más, pero Winsurf tiene también sus ventajas. Eh, entonces os recomiendo que lo que lo bajéis. Eh sirve para Windows, Linux, ¿vale?
¿Qué tiene, qué tiene eh Cursor o Winsurf? Tienen, es gratis hasta cierto punto. ¿Vale? Es gratis, eh os dan eh 50 requests por por mes, 200 eh completaciones por mes y os dan unos días de dos semanas de de pro con algunas limitaciones.
Si queréis todo, vale 20 dólares o 20 euros más IVA si lo hacéis desde aquí. Eh, pero entonces ya tendríais el las completaciones ilimitadas, los requests eh 500. Y bueno, y de hecho hay se puede utilizar algo que se llama el Max Mode, pero pagando más.
Secreto que me di cuenta hace unos pocos días. Mira, buscáis Cursor Student.
Si vais acá y verificáis el el estatus con la universidad, yo no lo hice con la UPC, no sé si yo lo hice con con con otra universidad. Me dieron un año gratis, ¿vale? Un año. Esto es una pasada porque, a ver, son 20 dólares, bueno, 22 por 12. Es un es un, entonces, si verificáis el estatus, os va os van a dar el curso por un año. Y eso es una es una, la verdad es que es una herramienta bastante poderosa y es poder hacer requests. Ah, por ejemplo, yo desde que lo activé, no sé, me quedan como dos semanas y me he gastado 100 o 200 requests hasta ahora. Pues pues si no es desarrollador, pues ni le alcanza, pero pues no somos desarrolladores.
¿Vale? Eh, entonces, bueno, ahí está el el este. Entonces, voy a voy a voy a comenzar la clase. La voy a dar desde Cursor, aunque la podéis tener en Colab, está en el repositorio.
¿Vale? Eh y eh y os mostraré, ¿vale? Os os estaré hablando, pero al mismo tiempo voy a introducir algo en en un notebook. ¿Vale? De pronto lo hago intercambiable.
Entonces cuando yo abro Cursor, que aquí lo tengo, ahora se me se va a abrir, ¿vale? Es un es un Visual Studio Code. Es igual, es la misma plantilla con algunas variaciones.
Eh, ahí me está abriendo el un workspace que yo tengo. Voy a cambiar el tema porque al al ser proyector esto esto no se ve bien. Voy a colocar un mono, creo que aquí tengo un Monokai Light.
Normalmente me suelen gustar más los temas de Monokai, ¿vale? Entonces ahí se ve mejor.
Eh, esto es un, esto es es un es una sesión que preparé para hoy para explicarles un poco de un notebook que tenía de hace un año que expliqué en un curso para muy muy básico de ingeniería de prompts. Pero lo he cambiado, ¿vale?
Antes usaba la Groq, que es una es una, hay unos modelos que es gratis, pero eh Google se puso las pilas durante todo este tiempo y actualmente ha llegado a a ser hacer bastante, o sea, a llegar arriba. No no no sé si es tal vez el mejor modelo que hay de lenguaje, pero es es uno de los mejores, el el de Google, Gemini. ¿Vale?
Entonces, lo que hice fue cambiar toda la estructura de la de la API a a usar eh Gemini.
Entonces, os voy a dar cómo usar la API de de de Gemini, pero usando la API de OpenAI. OpenAI es el estándar. OpenAI sacó hace, ya ya sabéis, a finales de 2022 el ChatGPT y ellos fueron los que dieron el punto de partida y desarrollaron la API de OpenAI, luego la actualizaron a la versión 1.0 y la utiliza muchas personas. Muchas, es un es un estándar.
Gemini tiene también eh Google tiene su propio SDK, su su propio eh sí, el el kit de de desarrollo y no está mal, pero como pero como OpenAI se usa la API de OpenAI serviría para la para OpenAI, para Groq, para, o sea, casi todos, incluso para Anthropic.
Eh, ¿vale? Entonces, antes de ir aquí, os voy a mostrar otra página que también la suelo usar, la suelo usar mucho, que es OpenRouter. ¿Vale? OpenRouter AI. OpenRouter es eh una forma de centralización de los modelos de lenguaje.
¿En qué sentido? Hoy en día tenemos eh Google dando los modelos de Gemini y Gemma. Tenemos a Anthropic con todos los modelos de tipo Cloud.
Tenemos eh ay, yo no puse, puse era. Ah sí. Eh, tenemos tenemos el OpenAI. Tenemos Mistral. Tenemos eh DeepSeek, que es muy bueno, DeepSeek. De hecho salió hace poco una actualización. Y tenemos un muchos proveedores que ellos mismos colocan los modelos y los ponen a a y ponen a cobrar por token, como por ejemplo eh Fireworks, si no estoy mal. Y bueno, Groq, que también es uno. Ah, bueno, y está el el el de el de Elon Musk, el el el XAI este que llaman, el el de el del antiguo Twitter, que ellos también tienen su modelo Grok, que es diferente, es un Grok con K, que también es es bueno. Y así tenemos un montón, ¿vale?
Entonces, ¿qué pasa? Claro, si vamos a usar modelos de lenguaje, esto se forma se vuelve una locura, porque entonces hay que ir al proveedor de cada uno de ellos y y y inscribirse, colocar la tarjeta, pagar, etcétera, etcétera, etcétera, ¿vale?
Lo que hace OpenRouter, como lo indica el nombre, es hacer un enrutamiento de todos los proveedores a través de ellos. Entonces, tú con una sola con una sola web, con un solo proveedor, tienes acceso a todos. O a o a la o a una gran mayoría.
¿Vale? Yo lo suelo usar porque yo aquí, por ejemplo, pago, tengo unos créditos, no mucho, y con esos créditos que coloco una la tarjeta, puedo usar muchos, ¿vale? Hoy hoy no lo usaremos porque usamos más más más Google.
Pero una cosa que tiene interesante son los rankings. Saber cuál es el mejor modelo de lenguaje es difícil. Porque evaluar los modelos de lenguaje, sobre todo los del estado del arte, es muy difícil. Y entonces, aunque existen, antes había una que se llamaba LMSYS Arena, que utiliza un sistema de Elo, de estos como el ajedrez, que la gente vota, ponen dos modelos de lenguaje a competir. Ah, uno le coloca un prompt para dos modelos de lenguaje, pero ocultando los modelos de lenguaje y uno vota cuál lo hizo mejor. Y con eso se hace un sistema de Elo y y organiza. Eso al comienzo funcionaba, pero ya no, porque está muy sesgado.
Entonces, uno de los mejores formas de saber cuál es el mejor modelo actualmente es está aquí. En los rankings. Ellos tienen unos rankings, no es una forma absoluta, pero da una da una muy buena idea.
Eh, y por ejemplo, aquí tiene un el el un leaderboard y está el top de esta semana.
¿Qué tenemos en esta semana? De primero está GPT-4 Mini. Seguramente porque es que es muy barato y es rápido. ¿Vale? Eh, pero está ahí, no sé por qué está ahí desde hace rato. GPT-4 o Mini, yo no lo uso casi. O sea, os lo digo. Y luego está Flash, y luego está Claude Sonnet 4, que salió hace una semana. Está Gemini 2.5 Pro y bueno, y ahí y ahí y ahí vamos.
O si queremos mirar el de este mes, eh es casi lo mismo, pero está Cloud, el que sonaba, el que estaba antes, o incluso el trending, que es quiénes están ahí como que salieron hace poco y lo están usando mucho.
Mira, DeepSeek. ¿Vale? Mira, y particularmente DeepSeek, este que salió hace nada, en estos momentos está gratis a través de de este proveedor. O sea, lo podríamos usar gratis. Con la API, ¿no? No estoy hablando del del chat, con con la API.
Y si lo quiero usar, ¿qué hago? ¿Qué cómo hacemos? Ah, aquí dice API. Y entonces, aquí está OpenAI Python. Otra vez. La API de OpenAI para el modelo DeepSeek.
¿Veis? ¿Por qué os dije? Y aquí está la la esta. Lo único que cambia es este este parámetro de aquí.
Pero si queremos ir a usar porque tengo el dinero y sé que es uno de los mejores modelos porque a mí, de hecho es de los que más uso, junto con Gemini, yo me la paso usando Gemini o Cloud, Gemini o Cloud.
Eh, tenemos a a Claude Sonnet. Tenemos varios proveedores porque Anthropic se tiene ellos mismos, tiene con Amazon, con Bedrock y a través de Vertex de de Google. O sea, está como bien distribuido. Y vamos aquí a la API. ¿Y qué tenemos? OpenAI OpenAI de de API. O sea, ¿sí? Entonces, básicamente cambiar un unas pocas cosas tiene.
Otra cosa que tiene esto es que nos dice cuánto cuesta. Es el mismo precio del proveedor, eso es muy importante. ¿Cuánto cuesta es muy importante? Porque si uno lo tiene para un negocio, lo que vale cada token es importante. Pero nos da información. ¿Qué tiene este modelo? Tiene un contexto de 200,000 tokens. Que hoy en día es bastante, pero no es el top, porque eh Gemini tiene hasta 1 millón gratis y hablando con ellos 10 millones. O sea, que es que es una pasada. Máximo de salida 64,000, lo cual está bien. Porque antes lo limitaban mucho a 8,000. Es decir, que lo máximo que saca en una tanda son 64,000 tokens. Bueno, o en o en total.
El token de entrada vale 3 dólares por millón de tokens, por millón. En la salida cuesta 15 millones, 15 dólares por millón de tokens. Y bueno, tiene la latencia y el drop out, que son como medidas de de velocidad, eh tokens por segundo y cuánto la latencia es cuánto, si no estoy mal, es cuánto se demora la primera el primer token en salir. Es más o menos, si no estoy mal. Igual aquí lo dice, mira. Tiempo medio para que el proveedor envíe el primer token, sí. Ahí está hasta los conceptos.
Entonces es una página que te da de referencia. Puedes usar lo que quieras, pero también tienes la información de los precios. Entonces está está está muy bien, ¿no?
Eh, y es una es es una está muy bien, o sea, la verdad es que es de las mejores páginas que pueden haber para esto.
Vale. Entonces, antes de comenzar, yo uso Gemini mucho de dos formas. Una es a través de la del Gemini App, que es como el el el chat GPT de de a ver si me cambio a a mi otra cuenta.
Esta es una que es como un como un chat GPT, como la web de chat GPT, pero de Google. ¿Vale? Y entonces aquí yo sé que yo puedo colocar y colocar y colocar y colocar y colocar y no me van a cobrar. Nunca.
Sí, sí hay que sí uno paga 20 dólares o 20 euros más IVA, por ahí 22 al mes, pero te dan 4 TB, eh te dan el Deep Research, que es una es una pasada, o sea, el Deep Research es una pasada. Que eso lo tiene OpenAI, pero te cobra 200 dólares el mes. Pero aquí no. ¿Vale? Que el de OpenAI es es algo más potente. Eh, puedes generar vídeos, etcétera, etcétera, etcétera.
Entonces tienes tienes esto aquí como para usarlo el día a día, para hacerle preguntas, para analizar imágenes, para investigar, para programar, tiene tienes un montón de cosas y aquí puedes escoger entre los dos eh mejores que hay ahora con ellos, que es el 2.5 Flash y el eh el 2.5 Pro Preview, que es el que más uso.
¿Vale? Es un es un lenguaje multimodal que acepta imágenes, vídeo, audio y texto, pero acá solamente imágenes y audio. En el otro ya ya lo veremos. Y tiene esto que es el Canvas, que lo creó realmente primero fue Anthropic, que es que si tú lo haces te crea un notebook aparte y te va programando, te va haciendo las cosas allí. ¿Vale? Entonces esto es bastante, es bastante, es bastante bueno.
¿Para qué lo uso yo? Este, por ejemplo, aquí cojo, le adjunto un PDF de un artículo y empiezo a a preguntarle cosas del artículo, tal, porque tiene un muy buen contexto, o incluso un libro.
Vale. Pero la otra forma que lo uso mucho es el el AI Studio.google.com. ¿Vale? Que es como el playground de OpenAI, que antes antes usaba. Si vais a a esto, os ya ya os vais a encontrar con esto. Es un playground. Es decir, es un es para jugar, para probar.
Tiene es gratis hasta cierto punto, pero luego cobra. Tiene limitaciones, pero sirve mucho para jugar. ¿Vale? Aquí encontraréis los modelos y las y las versiones de los modelos. Entonces, por ejemplo, aquí está Gemma o o Gemma, bueno, Gemma, que es los modelos open source de Google, totalmente abiertos, que sirve para hacer fine tuning y todo y todo eso y son muy buenos, de hecho son de los mejores que hay hoy en día abiertos. Pero luego está Gemini 2.5, que es lo mejor que hay ahora con ellos.
Entonces, ¿qué pasa? Aquí si os colocáis acá, os aparece esta ventanita donde dice, mira, input y output, otra vez, costo. Costo. Dice, eh si es menor a 200,000 tokens, en el contexto vale 1.25 dólares por millón de tokens o 10 dólares el output. Y si es mayor a 200,000 tokens, entonces vale más. ¿Vale? Y es gratis eh pero no sé si ahí lo dice, es gratis hasta cierto punto. Eh, a ver si si sale aquí. Es gratis. Bueno, no sale ahí, pero aquí por ejemplo sale eh en el Flash sí sale. Por ejemplo dice, tienes gratis 10 requests por minuto y 500 requests por day.
En el Flash. En el otro creo que son eh cinco requests por minuto y eh 50 requests por por day. ¿Qué significa? 50 veces que lo puedo usar, 50 llamadas o 500 llamadas en este caso durante todo el día, que está bien.
Y ese RPM, que es requests per minute, es qué tanto lo puedes usar en un minuto. Y dirás, pero si yo lo voy a usar de personal, pues me da igual, porque en un minuto hago es uno y eso. Pero cuando lo utilizáis la API, podéis utilizarlo si tenéis 100 personas al mismo tiempo, vas a hacer 100 requests en en en menos de un minuto. Entonces, claro, para aplicaciones sencillas, para pruebas va bien, pero para llevarlo a escala no. Y ahí es donde hay que pagar. Es lo que lo que está lo que está arriba.
Entonces eso es como la la información. Este es el que más que suelo usar muchísimo, ¿por qué? Porque aquí a con estos modelos, sobre todo con el el 2.5, los el el Gemini 2.5, cualquiera de los dos. Este creo que es mejor, es más nuevo. Tenemos eh podemos es un es un es un multimodal, pero en todo el sentido. Le puede entrar audio, le puede entrar texto, le puede entrar vídeos, le pueden entrar imágenes. ¿Vale? Saca texto eh y puede sacar voz y audio, pero en otras audios, pero en otras secciones, que eso no eso no lo voy a explicar, pero que están ahí a la izquierda donde dice stream. Eh, generate media. Bueno, tiene tiene más cosas, pero este que es el que más es eso.
Entonces aquí yo puedo entrar en un audio o un vídeo. O puedo decirle un vídeo un vídeo de YouTube o o o me bajo el audio y lo quiero analizar o lo quiero transcribir y con base en la transcripción quiero analizar. ¿Vale? Entonces yo he a veces he colocado eh, no sé, tengo una reunión y he grabado la reunión, como lo estoy haciendo ahora. Y cojo la reunión en vídeo y se la se la se la enchufo. Claro, me ocupa del millón de tokens 600,000 tokens porque la reunión duró una hora, o sea, un montón. Pero le digo, hazme un resumen, hazme un reporte de la reunión, y lo coge de una manera espectacular. Y fuera de eso, como fue vídeo, las cosas que se van colocando en una presentación, esa también las agarra. Entonces es una pasada. ¿Vale? Es una es una pasada porque esto es esto es y por eso me gusta tanto. ¿Por qué me gusta tanto el Gemini? Por el tamaño de contexto y por lo multimodal. Más que por la potencia. El más potente supuestamente es O3, el de OpenAI, pero es carísimo. Pero este está muy cerca. ¿Vale?
Entonces aquí se puede hacer muchas cosas, se pueden hacer pruebas, tal, con limitaciones.
¿Qué parámetros tiene? La temperatura, que ya os expliqué con lo de Transformer, y un y varias acá que son los tools, que ya hablaremos. Eh y aquí ahora los modelos hoy en día piensan. Piensan los modelos hoy en día. Se dieron cuenta en el entrenamiento que si le hacían un post entrenamiento pero enfocado hacia hacia pensar, que ya lo veremos, que es con una técnica que se llama CoT, Chain of Thought. Eh, se lo indujeron en el entrenamiento y entonces ellos ahora tienen una cadena de pensamiento y luego sí botan la salida. Y eso mejora mucho los resultados. ¿Vale? Entonces, eh incluso se puede controlar qué tanto quieres que piense. ¿Vale? Pero bueno, eso no, eso es para que lo lo probéis ahora.
Aquí, por ejemplo, en esto dice el código. Y mira lo que tenéis acá. Lo que tenéis acá es cómo usarlo con la API de ay, jolines, con la API de ah no, pensé que se había oído la con la API de ellos. No está con la de, no sé si estará aquí con la de OpenAI. No. Tienen de varios, pero tienes con la API de ellos. Vale. Por ahora.
Vale. Entonces esto era como para mostraros un poco lo lo lo que hay con respecto a a Google, que es el que más uso. Pero tenéis Anthropic, tanto la la la de pagar, que yo lo uso muchísimo. O sea, el de Cloud lo pago, lo he querido dejar, pero luego sacan Cloud 4. Eh, está OpenAI, que yo no lo uso, la verdad es que ChatGPT no lo uso hace más de un año, o sea, porque me parece muy caro, la verdad, es que tener que pagar 200 dólares al mes para poder usarlo como uso el de Google, no no no no no.
Sí, eh Vale.
Entonces ahora sí voy a a al al notebook.
Entonces os decía, como para resumir al al comienzo, que que os recomiendo que os bajéis Cursor, en la página cursor.com, le das a bajar. ¿Vale? No tenéis que pagar si verificáis que sois estudiantes, lo podéis tener un año gratis. ¿Vale? O sea, os estoy eh dando información de 22 x 12, o sea, más de no sé, casi cuánto. 400 algo, no sé, de de Eh, hoy no hoy no pienso mucho de de cálculos.
Vale, entonces, pero voy a ir aquí a explicar a explicaros esto del del notebook, ¿vale? En Cursor. ¿Eh? En Cursor.
Vale. Entonces, esto es Cursor es Visual Studio Code con una capa.
Ay. Perdón que está desconectado. Jolines.
Uy. Ya. No es que si no se me descarga, que va por la mitad.
Vale. Eh, entonces, esto es esto es esto es de toda la vida. Yo qué suelo usar mucho? Es una idea de programación, sirve para programar todos los códigos, lo uso lo suelo usar mucho para Python. Y tal y como lo usaba en Visual Studio Code, eh lo primero que hago cuando yo instalo esto es instalarle la la el el plugin de Python para poder correr Python. Y luego le instalo el plugin de Jupyter para poder usar Jupyter. Ya está.
¿Qué pasa? A mí me suele gustar mucho Jupyter y la forma de programar con Jupyter, más que con los scripts. ¿Por qué? Porque se puede visualizar, se puede ir paso a paso y para un lenguaje como Python que es un lenguaje de de interpretación de interpretado, va muy bien. ¿Vale? Entonces, suelo usarlo mucho con con Jupyter. ¿Vale? Como al estilo Colab.
Eh pero pero a lo mejor no es lo más cómodo aquí. Vale. Eh, entonces suelo usar, suelo instalar, sobre todo el de Python, que es el básico y el de y el de Jupyter, esos dos. Luego tengo otros para ayudar como eh el el visualizador de Excel o de CSV o el el visualizador de datos, eh una cosa de JSON, que no me acuerdo por qué, cosas como Markdown. Y algunos plugins, bueno, y tengo uno de R porque yo doy estadística también, entonces para tener R. ¿Vale? Pero bueno, eso es lo lo lo que lo que tengo acá.
Vale, entonces, voy a ver si puedo aumentar el tamaño de esto. Sí. Voy a quitar esto. Y todo lo voy a correr aquí.
Cuando tenéis, cuando tenéis eh cuando tenéis esto, a ver si puedo quitarlo, bueno, y si no lo sigo dando ahí. Cuando tenéis esto, es importante en con Jupyter se utilizan los que se llaman los kernels. Es decir, tú puedes crear diferentes tipos de kernels para correr el el notebook. Yo tengo, aquí yo yo puedo seleccionar, ¿vale? Y aquí tengo varios. Tengo uno para la clase, que se llama AB2025. ¿Sí? Donde yo he he ido instalando todos los paquetes que voy utilizando para la clase. Entonces ahí tengo Pytorch, Pytorch, tengo Pandas, Y he utilizado algo que se llama UV. Que o UV, que es una nueva forma de instalación de Python, pero que no no es no es de la clase, que es muy rápida. Pero tengo otro que se llama LS San Nuke, que lo utilizo mucho para cosas de APIs y de modelos de lenguaje para poderlo llamar. De hecho LS es Langchain, que luego lo lo hablaré al final. ¿Vale? Este es el que lo el que usaré aquí.
¿Qué necesitáis para poder usarlo? Tenéis que instalar un environment, aunque sea. ¿Sí? ¿Cómo lo podéis hacer? Con Conda o con o con UV. Listo. Entonces, si vosotros decís esto qué esto qué es? ¿Qué cómo instalo esto? ¿Sí? Él él mismo cuando tú lo seleccionas acá y le dais seleccionar, no sé, otro kernel, eh y aquí Python environment, si le dices aquí aquí puedes crear uno. Uno nuevo, o sea, todo con click.
Pero si quieres hacerlo a través de consola, entonces ahí es donde empezamos a usar el panel de inteligencia artificial. ¿Vale? O sea, voy a ir os voy a ir explicando cada cada cosa. Esto son cosas que que hice para la la clase, yo lo uso mucho para la clase también.
Este panel, espera, quito esto. Que aparece a la derecha era lo que antes ellos llamaban Composer y que en Winsurf le llama eh Cascade o cascada. Pero básicamente es un panel de de IA. Es un panel para hablar, comunicarse con el modelo de lenguaje. ¿Vale? Y tiene tres tres modos. El modo agente, el modo Ask o Agent, Ask y manual. ¿Vale? El que más uso yo es el Ask y el y el de agente. ¿Vale? El manual es más eh propio.
Entonces, ¿qué es? Es un panel donde yo quiero preguntarle cosas. ¿Cómo? Como si estuviera ChatGPT o o el este Gemini pero al lado. Pero él con el con un contexto determinado. Entonces, si yo cojo el notebook y lo y lo toco, él automáticamente lo adjunta el notebook. ¿Sí? Y le puedo hacer una pregunta.
Entonces yo quiero hacer una pregunta aquí. No que me modifique nada y y tengo un montón de modelos. ¿Por qué? Porque una de las cosas que me gusta de Cursor es que si tú vas aquí, que son los settings y vas a models, tarán, montones de modelos, incluso puedo agregar más modelos. Entonces aquí tengo, tengo Cloud Sonnet normal y con pensamiento. El 35, que es uno de los que más me gusta. El Gemini, los más poderosos, GPT 4.1. El Cloud 37 Sonnet, ambos. Uno que es de ellos propios. El O4 Mini. El DeepSeek, el que salió hace poco. Eh y ellos van colocando, tengo Groq, tengo incluso O3, pero para O3 hay que pagar. Eh, todos los que dicen Max hay que pagar, son muy potentes, pero hay que pagar. Max es que utilizas el contexto full. Eh, y y así y hay más. E incluso puedes meterle de OpenRouter modelos de OpenRouter. O modelos de OpenAI pagando o de Google pagando. Entonces eso es de las cosas que más me gusta de ellos. Estos que están aquí por defecto son los que puedo utilizar 500 veces al mes. ¿Vale? Eh, excepto los de Max, que hay que pagar.
¿Qué pasa? Que yo utilizo mucho Cloud. Sí, porque Cloud me gusta mucho para lo del código. Para código. Y Gemini, pero Cloud para funcionar como agente, es decir, comunicarse, que ya hablaremos un poquito de eso, comunicarse con con poder hacer cosas por sí solo, hacer utilizar lo que se llaman las tools. Es es es es uno de los mejores, si no el mejor. ¿Vale?
Eh, entonces, aquí yo tengo el notebook y yo le voy a y le puedo preguntar, dime.
Acerca del Ask y el agente, ¿cuál qué diferencia tiene?
El Ask es preguntar solamente. El agente es darle poder autónomo para que ejecute cosas y cree con permisos. Ya ya lo lo lo miramos.
Y cómo es luego también te voy a preguntar cómo seleccionas el modelo pues mejor que te vaya.
No, porque yo por la experiencia, pero normalmente normalmente el que yo más recomiendo está entre Cloud, eh está el Gemini y está eh los de OpenAI, o sea, por ahí, pero también.
Para código, solamente.
Todo, no, no no, no, tú puedes incluso preguntarle cosas que no sean de código, pero normalmente está orientado hacia el código. Cursor tiene por detrás algún system prompt que lo orienta más hacia el código, pero yo yo le he podido preguntar cosas.
Entonces, yo me voy a olvidar por ahora del contexto. Voy a coger aquí a Cloud y le voy a preguntar, quiero crear un nuevo eh environment de Python. ¿Cómo lo hago? Lo podéis hacer aquí en castellano, no necesita que sea en inglés. Quiero eh crear un nuevo environment de Python eh usando, por ejemplo, que es estándar, conda. Eh, ¿en qué sistema operativo? No sé, porque eso también es importante. En Linux, en este caso. Eh, por favor, ayúdame al respecto. A veces suelo ser muy cordial, a ver si lo hace mejor. Entonces lo doy, lo mando y ahí va generando, se comunica, el internet de aquí es muy malo y aquí está. Pasos. Abre si está instalado, cómo crearlo, activar, verificar, entornos, tata. Ejemplo práctico, aquí copie, aquí run si quiero correrlo, etcétera, etcétera, etcétera. ¿Vale? Solamente preguntando, ¿eh?
Entonces, con respecto a preguntar, hay dos formas de utilizar esto. Son estas son terminologías muy nuevas que han aparecido en menos de un año. Bueno, hay una que no. Pero está muy de moda algo que se llama el Vibe Coding, que es que lo que lo estos términos normalmente los los origina siempre Andrew Karpathy. Pero eh es Vibe Coding es darle una instrucción y que él haga todo y uno medio revisa. ¿Vale? Eso está bien, yo lo yo lo he usado así, pero es peligroso porque si hay bugs o algo y uno no sabe lo que está haciendo, es difícil identificarlo, es difícil dónde ver dónde está el error. Eh, no se entiende el código, es peligroso. ¿Sí? Para algo rápido y sencillo tal, pero si yo voy a hacer una aplicación en producción a escala, eso es muy peligroso. ¿Vale? Se puede se puede hacer si lo sé hacer, si voy dándole pautas.
Y la y lo otro eh el otro modo es lo que llaman el Pair Programming. Pair Programming, que es un término así mucho más viejo, se usaba cuando se iba a programar, una persona programaba el código y otra persona al lado o en remoto le hacía comentarios. Entonces uno va programando y la otra persona le dice, mira, ¿por qué no pruebas esto aquí, no será mejor? Entonces él va el programa. Mira, ta ta ta. O si se comunican en con para compartir un notebook o algo, entonces lo van haciendo al mismo tiempo. ¿Vale? Y uno uno es como el consejero y otro es como el que el que programa.
Aquí también no se puede hacer tan directamente, pero sí que se puede hacer con el modo Ask o como o en el agente, pero teniendo cuidado. Para mí la más la más bonita es es el Pair Programming, es utilizar la inteligencia artificial como un compañero, como un asistente o como un amigo que uno le pregunta, le da ideas y te retroalimenta. ¿Vale? Porque así es como más aprende. ¿Sí?
Eh, no es una plataforma enteramente esto de de pair programming, pero se puede usar. Es es esto es una plataforma más de Vibe Coding, pero no al extremo tampoco, se puede usar los dos.
Luego hay una cosa que se llama, por ejemplo, Cloud sacó algo una cosa que se llama Cloud Code, no, sí, Cloud Code. Eh, Google sacó hace poco Jules, que se llama. Eh, OpenAI sacó otro también que se llama Codex. Eh, que son agentes completamente autónomos para para programar. Tú le dices, quiero esto, esto y esto y ¿sabes qué? Ve solo. Y lo haces y eso empieza a gastarse tokens por montones y empieza a programar, a programar, a programar, a probar, a programar, a programar y estás ahí a lo mejor funciona o no y tienes que hacer pruebas y tal. Eso, por ejemplo, es Vibe Coding, pero al al extremo. Vale.
Bueno, entonces esos esos dos términos son son importantes tenerlo en cuenta, el Pair Programming y el y el. Entonces, esto es una forma que si no lo tenéis, para instalar, lo podéis usar, así como yo hice y lo vais copiando, aquí yo suelo abrir una terminal, porque pero estoy en Linux. Eh, y en la terminal voy ejecutando las cosas que me dice, voy probando, copiando y pegando, soy muy clásico al respecto. Pero a veces utilizo el Vibe Coding, ¿vale? A veces lo utilizo, yo creo que cada vez más. ¿Vale?
Eh, vale. Entonces, ahora sí me voy hacia hacia lo de lo de hoy.
Eh, esto es, aquí hay que usar la API de Google. ¿Vale? ¿Cómo vais a utilizar la API de Google? Lo voy a hacer, lo voy a hacer al mismo tiempo con con vosotros para que lo lo hagáis. En en Google, en AI Studio, que todos lo tenéis acceso, eh a ver si por acá, aquí a la derecha dice Get API, Get API key. Si le dais click, os aparece esto. ¿Vale? En esta parte de abajo, ah, perdón, ahí arriba le dais a create API key y podéis crearla. Ya está.
Yo tengo esta pagando, porque a veces utilizo de más o a veces eh quiero hacer utilizar el buscador y pago, pero normalmente no me llega más de un dólar al mes y y eso. O o puedo crear una, la voy a crear para solamente para probar y la voy a llamar eh eh ah no no, no me dice que seleccione un proyecto. Eh, vale, bueno, voy a seleccionar el mismo. Eh Sí, hay que seleccionar un proyecto. Bueno, da igual. Selecciono esto y le digo crear. Me crea una nueva API por aquí abajo. Me aparece una vez. Como os digo, luego la voy a borrar. Termina en Ubu, así que luego la borraré.
Copio y en el código, el código que os he puesto, os va a aparecer una una ventana cuando ejecutas o directamente podéis colocar Google API key y pegas. Lo que pasa es que no se suele no se suele hacer, aquí lo estoy haciendo, pero eso no se suele hacer, porque la la API key es algo privado. Si esto lo pongo en internet y cojo el video el vídeo y lo publico en YouTube y se me olvida borrar la API, mi cuenta de Google va a estar, ¿vale? Es peligroso, ¿eh? Entonces, esto que voy a hacer no se debe hacer.
Ejecuto esta esta celda y él él él mira si si está si estamos si está en Colab, hay una cosa que llama Secrets, pero aquí os va aparece una ventana para pegar precisamente la API key. Le doy enter y ya tengo la, ah sí, bueno, ya la ingresé manualmente. Y ahí ya lo puedo usar.
Entonces, una vez que ya lo he ya lo he hecho, eh fijaos que él llama a el client OpenAI. Coloca el API key, que era este código largo y en base URL está la API en la dirección para poder usar la API de OpenAI con Google. Eso es lo lo único que se necesita. El del modelo vamos a escoger el Gemini 2.0 Flash y y ya está. ¿Vale? Entonces lo ejecuto y ya está.
Y esto no. Entonces vámonos hacia hacia hacia lo que se llama prompt crafting o ingeniería de prompts o prompt engineering.
Esto que está aquí es ah, espera que aquí creo que le di un enter sin querer. Sí. Ah, bueno, no importa. Eh, se me fue para allá. Si tiene si tenéis el mismo error que no creo, es simplemente hacerle así.
¿Qué pasa? Eh esto es una, esto es como usar la la API. ¿Vale? Es una, le voy a dar Alt Z para que me muestre, me parta en líneas.
Entonces aquí vamos a definir una función con un user, con un mensaje de usuario, un mensaje de de de system, lo que llaman el system prompt y el system prompt es un mensaje, mira, eres un un modelo de lenguaje que solo ejecuta eh lo que se llama text completion. ¿Vale? Vas a predecir las siguientes palabras usando tokens, ta ta ta. Esto por qué lo hago? Porque para algunos ejemplos no todos me va a salir. Estoy suponiendo que el modelo es un modelo de lenguaje básico, no un modelo de chat. Este es un modelo de chat. ¿Vale? Es es por eso que lo hago.
Y aquí, pero donde está lo importante es acá, esta es la API de OpenAI. Esto que dice client chat completion create, aquí se le da el modelo, el mensaje, los mensajes y la temperatura del modelo. Vale, que la temperatura la colocamos por defecto 07 y aquí lo que está haciendo es que lo que hace es coger un diccionario, una lista, perdón, y los va anexando uno con otro. El el rol que es el system con el contenido, que es el el system message y aquí el rol que es el user con el user message y luego produce la respuesta y luego se va juntando y se va juntando así sucesivamente. Y se crea toda la historia.
¿Vale? ¿Qué es lo importante ahí? Lo importante es que en un modelo de lenguaje, sobre todo de chat, hay eh digamos como tres clases de mensajes. El el system prompt o el system message, el mensaje de system, que es un mensaje donde se le puede direccionar con mayor fortaleza qué va a hacer el modelo. ¿Vale? Entonces si tú le dices eh esto es tú eres un chatbot eh que habla solo de estadística y no puedes hablar de nada más. Él y lo lo fuerzas a eso, él en la gran mayoría porque esto también se puede hackear, lo va a hacer así. Si tú le dices eh háblame, escríbeme de forma inversa, lo va a hacer así. ¿Vale? Y en el user es como un usuario.
Entonces, si tenéis una aplicación en en un eh vas a generar un chatbot, lo que normalmente se pone al al usuario es el user. El system nunca, porque el system es un peligro, el system con el system se puede hacer de todo. Entonces es como como un un un prompt de administrador, de admin y el otro es el de un usuario. Es básicamente la la diferencia. Eso es muy importante. Y luego entonces está el el user, el system y luego la respuesta, ¿no? Que es como el el el mensaje de de de inteligencia artificial de AI. ¿Vale? El y ya está.
Esto es. Entonces esto simplemente con el modelo de Gemini, pero esto lo podemos cambiar por muchos modelos. Entonces lo ejecuto y ya está.
Entonces aquí le digo, mira, eh imprímeme eh como solamente la función, le das un user y ya ya está direccionado, le digo, explica brevemente qué es un transformador, qué es un transformer en IA. Lo hago y ahí me bota la el resultado. ¿Sí? ¿Vale? No me gusta que no se vea todo, ¿sí lo veis? Porque no no se parte.
Os voy enseñando en en en en Cursor de una vez que que no quiero esto, no lo quiero, es que no no lo puedo ver. Si veis acá, aquí dice algo que dice Quick Edit, que es control K, control K. Si le doy control K, este es otro modo que tiene Cursor y tiene Winsurf. Y es selecciono el código y le digo qué quiero hacer en ese código, no es un chat. Es editar el código con unas instrucciones. Y le voy a decir, mira, eh haz eh que se imprima el mensaje en varias líneas. Ya está. No es chatear, ¿eh? Yo no estoy hablando ni le estoy diciendo, no.
Pero no me que dijo ejemplo rápido. Eh ya. No me entendió. Eso puede pasar. No no no no no no. Haz que se imprima, pero ¿cuál mensaje? Es que parece que sé claro. Haz que se imprima, imprima el mensaje de respuesta en varias líneas porque cuando se eh imprime en una celda queda muy largo.
Está tonto. No no no no no no. Voy a ponerle el 35, mira que es un es uno es uno de antes. Mira. Pero no, pero luego lo interpreta como unas líneas. Aquí me está haciendo quedar mal, eh. Vamos a a darle con un con un no sé, no, no lo hace, no pero es porque no me no me estoy sabiendo explicar. Estoy casi seguro, no creo que lo lo tome.
Claro, como no tiene el contexto de la función, él piensa que es esto. Mira, ahora sí lo hizo. ¿Ves? Mira, me gustó mejor el 37. Esto es lo que necesito, un text wrap que coge la respuesta y le da un máximo de 80. Vale. También, la verdad es que yo suelo utilizar más inglés. Aquí aquí lo hago, pero mira, ¿veis que no estoy importando? No he importado, pero él intuye que tengo, intuye no, predice que tengo que importar. Le doy un tap y listo. Es como el del Gemini.
Entonces una de las cosas que tiene Cursor más potente es lo que se llama el la completación, esto que es ilimitado cuando se tiene el pro, es que él te predice y lo hace muy bien. Con apuntas de tap tap tap tap tap tap, tú puedes programar a una velocidad muy rápida. ¿Vale? Es un modelo de, de hecho, de lenguaje base, pero pero que predice, le llama fill in the middle. Que utiliza lo de atrás y lo de adelante para hacer la el completo. Entonces ahora sí le voy a dar y lo ejecuto.
Mira, ahí está. Ahora puedo ver en varias líneas. Un transformer es un modelo, tata. Eso era como un ejemplito ahí que me hizo quedar mal Cloud. Pero es porque no no me no me supe explicar.
Entonces, yo solamente voy a explicar algunas técnicas muy sencillas de de prompting y luego os os digo dónde hay más. Cuando cuando esto comenzó, se dieron cuenta, la primera técnica se llama few-shot prompting. Few-shot prompting es dar ejemplos. ¿Vale? Entonces, cuando esto era un modelo de lenguaje, no uno de chat, que predice palabra a palabra, eso es como si fuera así. Le le decías, eh le podías colocar como como ejemplos, mira, le coloco aquí el mensaje en inglés, en castellano, en inglés, en castellano y aquí le coloco en inglés y el que me tiene que dar castellano. No había instrucciones, no era un modelo de chat y él con los ejemplos aprendía y predecía. ¿Vale? Entonces cuando lo corría, pues lo lo hace. Pero ojo, estoy usando un modelo de chat, ¿no? Sino que lo estoy obligando a que me prediga así, pero a veces no sale tan bien.
Eso es lo primero. Few-shot prompting es ejemplos. Siempre cuando se escriben prompts es muy bueno dar ejemplos. Porque le ayudan a darle contexto al modelo и ayuda a orientarlo. Eso eso se sigue usando hoy en día. ¿Vale?
Vale. Eh, perfecto. Luego está este, Chain of Thought. Esa es la técnica más importante de todas. Tan importante que luego se convirtió en eh luego lo tomaron para entrenar los modelos, hoy en día los modelos ya ya hacen esto implícitamente. ¿Vale? Es que se instruye al modelo para que piense.
Entonces, ahí había dos formas, el el CoT few-shot que era con ejemplos, entonces se le dice, eh hay dos locutores o dos personas, entonces aquí la tienes el que pregunta y luego la respuesta. El que pregunta y la respuesta, pero en la respuesta se le da como una especie de de paso a paso. Sí, Jean tiene el doble de la edad de Steve, Jean tiene 12 años, ¿cuántos años tiene Steve? Y entonces acá en la respuesta le colocamos en forma de ecuación, 12 es igual a 2 * A, donde A es la edad, dividiendo ambos lados por dos, vemos que A es igual a 6. Se le da un ejemplo de que tiene que razonar. Y luego aquí se le hace otra pregunta y él aquí tendría que razonar y preguntar. No lo va a hacer porque esto no es un modelo de chat, yo ya lo probé. No es un modelo de de esto, sino es un modelo de chat y no lo hace. Me da la respuesta, pero no no no lo piensa.
Ah no, sí, mira, me hizo quedar mal. Como esto tiene aleatorio, mira, lo hizo bien. Cada panadero tarda una hora en hacer un pastel, ah no, bueno, más o menos pensó.
Y luego está el zero-shot CoT, que que es el más famoso dentro del dentro del del Chain of Thought, que es en vez de darle ejemplos, alguien, incluso fue un paper, esto fue un paper. Dijo, digámosle que piense paso a paso. No más. Y con el el paso a paso, ya empezó a a a generar mejores respuestas. Entonces, le puedes le puedes eh a ver. Voy a ejecutar.
Mira, entonces él dice, ah, un panadero tarda una hora en hacer un pastel, así que tres panaderos tardarán una hora en hacer tres pasteles, la respuesta es una hora, porque pensó. No no dio la respuesta, la respuesta es una hora. No, sino pensó. Entonces, se dieron cuenta que si tú pones a pensar entre comillas al modelo, claro, esto es un modelo de lenguaje, ¿cómo así que pensar? Lo que hace es que él va generando tokens de tokens tokens razonando. Y toda esa información como la usa para generar, ayuda a a resolver el problema de forma más más eh contundente. En vez de generar la respuesta de una. ¿Vale? Es eso, pero se parece a nosotros. Vale.
Otra técnica es la imitación de documentos, se suele usar mucho también. Si tú coges y utilizas eh se también se se han dado cuenta que si se nota que estos modelos de lenguaje se usan con con muchas cosas de internet y en internet hay mucha información estructurada. Hay información estructurada en HTML, XML y en Markdown. Entonces, estos modelos normalmente si se suele ser ordenado y se le suele dar un formato más estricto en como Markdown, aquí IT Support Assistant, y aquí el customer y aquí el support assistant, como si fuera un chatbot, ¿no? Eh, es como que ah dice, ah, mira, aquí hay un subtítulo, esto es una persona, esta es otra persona, esto es es un chat de tal y y él le da pistas al el esta estructura le da pistas al modelo sobre sobre la comunicación o la o la estructura. ¿Vale? Este no lo he corrido, no sé qué me dé. La verdad. Oh no, mira.
Y ahí empieza a generar un pero esto no me gusta. Entonces voy a hacer lo de voy a hacer lo de antes. Lo voy a seleccionar aquí. Lo voy a dar control K y le voy a decir eh usa eh text wrap. A ver si me lo hace bien. A ver. Ahora sí. ¿Ves? Ya me lo hizo. Ahora sí lo puedo leer.
Entonces, si veis, esto que está aquí es el pron que yo le metí. Pero este es el pron que él entiende. Este es el pron que yo le metí. Eh, ah no, perdón, este es el pron y esta es la respuesta. ¿Vale? Entonces es una cosa así como de de Markdown. ¿Vale?
Eh, vale. Y luego, otra cosa que está muy de moda es el XML prompting. XML prompting es lo mismo, pero usando XML. Y esto lo usa mucho Anthropic. Anthropic, de hecho, recomienda que uno haga los prompts usando XML. ¿Por qué? Porque el XML tiene una estructura más rígida, más fuerte y el modelo se orienta mejor. Entonces, aquí le estoy diciendo, mira, este es un assistant. Este es el user. Este es el assistant. Ta ta ta. Y aquí al final, ¿qué me tienes que dar? La respuesta del assistant. ¿Vale? Entonces, si yo lo ejecuto, pues me tiene que dar una respuesta similar. ¿Vale?
Mira, ahí está. Bueno, no me lo hizo como yo quería porque no le puse el system prompt. Pero bueno, es es es es lo mismo. ¿Vale?
Eh, y para terminar, esto es una cosa muy sencilla, es el metaprompting. ¿Qué es el metaprompting? Es utilizar un LLM para que te genere prompts. Y esto lo hace muy bien Cloud. Cloud es muy bueno generando prompts. Entonces, aquí hay un ejemplo. Dice, mira, quiero que seas un experto en Python y quiero que me crees un prompt para pedirle a un LLM que me genere un código. Y entonces él te genera el prompt. Y esto se usa muchísimo, pero para cosas más complejas. Si tú tienes, si tú quieres, por ejemplo, hacer un una gente que te haga muchas cosas, es mejor utilizar un LLM para que te genere los prompts. ¿Vale? Y lo hace muy bien.
Eh, listo. Esto era lo que quería mostraros. Entonces, ahora, lo que yo quería de mostraros y lo voy a hacer aquí, voy a hacerlo de de una vez. Resulta que yo tengo esto que es ejercicio final. Tengo en un PDF, ¿sí? A modo de de de de prueba. Y eh tengo aquí el repositorio de nosotros. ¿Sí? ¿Os acordáis? Entonces, voy a hacer un ejemplo. Le voy a decir, tengo pereza. Yo yo esto lo puedo hacer, o sea, yo le puedo hacer Git add. Git commit -m, Git push. Y actualizo el Readme.
Entonces, le voy a decir, mira, actualiza el Readme eh con eh los archivos nuevos del eh de la carpeta S9 del repo AB2025, para que no se me vaya a perder, porque eh sigue el mismo formato del Readme. Después haz pero espera porque antes de eso, porque me creo que me va a tocar, si no aquí la porque hace poco le di, déjenme un segundo, GH out eh esto sí me toca hacerlo, out switch. Es que yo tengo otro usuario y si me toca cambiarme, ya, así me cambié, si no no lo puedo no lo puedo hacer.
Y eh después haz eh un push al repositorio, al repo de GitHub. Así, ya.
No está bien. Lo miró. En modo agente, lo actualiza, coge el Readme, lo lee, lo actualiza, me mira cuál es la diferencia, entonces yo lo observo porque tiene un diff. Ah, mira. Entonces digo, esto es lo que ha cambiado y aquí le agregó eh final exercise PDF ahí. Yo le digo, está bien. Le digo eh le puedo decir aquí aceptar o aceptar todo aquí. Acepto y luego entonces me dice, listo, ya lo tengo. Ahora hagamos el eh quiero quiero hacer el commit. Entonces primero voy a ejecutar, me voy a ir al directorio y le voy a hacer un Git status a ver cómo está. Él mismo. Yo no lo tengo automático para que que me pida preguntar si sigue o no. Entonces dice, ah, mira, parece que el path es diferente. No sé, espero que no se líe. Porque no ese no es el repo. Ese no es el repo. Ahí se está equivocando.
En esto Winsurf es mejor. Entonces lo voy a copiar el path porque ya ahí se está pegando la la esta, digo, no, el path el path es este.
Porque se ya sé que se va se va a liar, porque está mirando en el otro. Ah, perfecto, ahora sé que este no es el correcto, entonces ahora le doy Git status, archivos sin añadir, ta ta ta, sin cambios, voy a hacer el commit. Ta ta ta y luego voy a hacer ahora un un commit, él mismo lo generó. Ta ta ta y luego voy a hacer el el push a GitHub. Ta ta ta, perfecto. Y entonces ahora voy yo aquí. Esto es un ejemplo sencillo y luego me hace el resumen de todo lo que hizo.
Y luego yo voy aquí, voy al repo.
Ah.
Claro. Es un ejemplo muy sencillo, eso tiene un panel para hacer todo esto a la izquierda con GitHub, pero es un ejemplo sencillo de yo no sé, yo me lío a veces con cosas de de GitHub, yo me lío a veces y esto para mí ha sido una maravilla, porque no tengo que estar mirando, ay, quiero hacer el este, mira, aquí está. Este es el ejercicio. ¿Vale? El ejercicio es que yo estoy grabando un audio, os lo voy a pasar y vais a tener que hacer esto. Pero usando Cursor, o sea, no desde cero, no más.
¿Vale? Eh, y ya está.
Entonces lo tengo que hacer yo. Entonces lo primero que tengo que hacer es parar el el audio, el video, el vídeo. Ahí entonces hasta aquí va.
Detener.