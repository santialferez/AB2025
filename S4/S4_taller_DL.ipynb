{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller de Deep Learning Básico\n",
    "\n",
    "## Índice\n",
    "1. [Introducción](#introducción)\n",
    "2. [Descenso de Gradiente con NumPy y PyTorch](#descenso-de-gradiente-con-numpy-y-pytorch)\n",
    "3. [Regresión con Red Neuronal de Una Capa](#regresión-con-red-neuronal-de-una-capa)\n",
    "4. [Clasificación con Fashion-MNIST](#clasificación-con-fashion-mnist)\n",
    "5. [Recursos Adicionales](#recursos-adicionales)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "Este taller está diseñado para proporcionar una introducción práctica al Deep Learning utilizando PyTorch. A través de ejercicios prácticos, exploraremos conceptos fundamentales como el descenso de gradiente, la construcción de redes neuronales simples para regresión y clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descenso de Gradiente con NumPy y PyTorch\n",
    "\n",
    "### Ejercicio 1: Optimización de una función simple\n",
    "\n",
    "#### Parte A: Implementación con NumPy\n",
    "\n",
    "Consideremos la función simple:\n",
    "\n",
    "$$R(\\beta) = \\sin(\\beta) + \\frac{\\beta}{10}$$\n",
    "\n",
    "**Tareas:**\n",
    "1. Dibujar una gráfica de esta función en el rango $\\beta \\in [-6, 6]$.\n",
    "2. Encontrar la derivada de esta función (a mano).\n",
    "3. Implementar el descenso de gradiente para encontrar un mínimo local:\n",
    "   - Punto inicial: $\\beta^0 = 2.3$\n",
    "   - Tasa de aprendizaje: $\\rho = 0.1$\n",
    "   - Visualizar cada iteración en la gráfica\n",
    "4. Repetir el proceso con $\\beta^0 = 1.4$.\n",
    "\n",
    "**Sugerencias:**\n",
    "- Para graficar la función, utiliza `numpy.linspace` para crear un rango de valores de $\\beta$ y `matplotlib.pyplot` para visualizarlos.\n",
    "- La derivada de $\\sin(\\beta)$ es $\\cos(\\beta)$. ¿Cuál es la derivada de $\\frac{\\beta}{10}$?\n",
    "- Para implementar el descenso de gradiente, recuerda la fórmula de actualización: $\\beta^{t+1} = \\beta^t - \\rho \\cdot \\nabla R(\\beta^t)$\n",
    "- Puedes usar un bucle para iterar el proceso de actualización y almacenar los valores de $\\beta$ en cada paso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código inicial para ayudarte a empezar\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definir la función\n",
    "def R(beta):\n",
    "    # Tu código aquí\n",
    "    pass\n",
    "\n",
    "# Definir la derivada de la función\n",
    "def dR(beta):\n",
    "    # Tu código aquí\n",
    "    pass\n",
    "\n",
    "# Rango para graficar\n",
    "beta_range = np.linspace(-6, 6, 1000)\n",
    "y_values = R(beta_range)\n",
    "\n",
    "# Graficar la función\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Tu código aquí\n",
    "\n",
    "# Implementar descenso de gradiente\n",
    "def gradient_descent(beta_init, learning_rate, num_iterations=50):\n",
    "    # Tu código aquí\n",
    "    pass\n",
    "\n",
    "# Ejecutar descenso de gradiente con beta_init = 2.3\n",
    "# Tu código aquí\n",
    "\n",
    "# Graficar los puntos del descenso de gradiente\n",
    "# Tu código aquí\n",
    "\n",
    "# Repetir con beta_init = 1.4\n",
    "# Tu código aquí\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parte B: Implementación con PyTorch\n",
    "\n",
    "Ahora implementaremos el mismo ejercicio utilizando PyTorch para calcular automáticamente las derivadas y actualizar los pesos.\n",
    "\n",
    "**Sugerencias:**\n",
    "- En PyTorch, necesitas crear tensores con `requires_grad=True` para que PyTorch calcule automáticamente las derivadas.\n",
    "- Usa el método `.backward()` para calcular la derivada de la función con respecto a los parámetros.\n",
    "- Recuerda reiniciar los gradientes con `optimizer.zero_grad()` o `tensor.grad.zero_()` en cada iteración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definir la función en PyTorch\n",
    "def R_torch(beta):\n",
    "    # Tu código aquí\n",
    "    pass\n",
    "\n",
    "# Rango para graficar\n",
    "beta_range = torch.linspace(-6, 6, 1000)\n",
    "y_values = R_torch(beta_range)\n",
    "\n",
    "# Graficar la función\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Tu código aquí\n",
    "\n",
    "# Implementar descenso de gradiente con PyTorch\n",
    "def gradient_descent_torch(beta_init, learning_rate, num_iterations=50):\n",
    "    # Inicializar beta como un tensor que requiere gradiente\n",
    "    beta = torch.tensor(beta_init, requires_grad=True, dtype=torch.float32)\n",
    "    \n",
    "    # Tu código aquí para implementar el descenso de gradiente\n",
    "    \n",
    "    return beta_history\n",
    "\n",
    "# Ejecutar y visualizar el descenso de gradiente\n",
    "# Tu código aquí\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión con Red Neuronal de Una Capa\n",
    "\n",
    "### Ejercicio 2: Predicción en el Dataset de Diabetes\n",
    "\n",
    "En este ejercicio, utilizaremos el conjunto de datos clásico de Diabetes para predecir una medida cuantitativa de progresión de la enfermedad un año después de la línea base.\n",
    "\n",
    "**Descripción del Dataset:**\n",
    "- 442 registros\n",
    "- 10 características numéricas (edad, sexo, IMC, presión arterial, y seis mediciones de suero sanguíneo)\n",
    "- Variable objetivo: medida cuantitativa de progresión de la enfermedad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Cargar el dataset de diabetes\n",
    "diabetes = load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convertir a tensores de PyTorch\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
    "y_train_tensor = torch.FloatTensor(y_train).view(-1, 1)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
    "y_test_tensor = torch.FloatTensor(y_test).view(-1, 1)\n",
    "\n",
    "# Crear TensorDataset\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Crear DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Ejemplo de impresión de tamaño\n",
    "for xb, yb in train_loader:\n",
    "    print(f\"Batch X shape: {xb.shape}, Batch y shape: {yb.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 2: Definir la Red Neuronal\n",
    "\n",
    "**Tarea:** Define una red neuronal simple con una capa oculta utilizando PyTorch.\n",
    "\n",
    "**Sugerencias:**\n",
    "- Crea una clase que herede de `nn.Module`\n",
    "- Define las capas en el constructor (`__init__`)\n",
    "- Implementa el método `forward` para definir cómo fluyen los datos a través de la red\n",
    "- Considera usar una capa oculta con activación ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # Define aquí las capas de tu red neuronal\n",
    "        # Sugerencia: usa nn.Linear para capas completamente conectadas\n",
    "        # y nn.ReLU (o similar) para funciones de activación\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Define aquí cómo fluyen los datos a través de las capas\n",
    "        pass\n",
    "\n",
    "# Parámetros de la red\n",
    "input_size = X_train_tensor.shape[1]  # Número de características\n",
    "hidden_size = 20  # Tamaño de la capa oculta (puedes experimentar con este valor)\n",
    "output_size = 1  # Una salida para la regresión\n",
    "\n",
    "# Crear el modelo\n",
    "model = SimpleNN(input_size, hidden_size, output_size)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 3: Entrenamiento\n",
    "\n",
    "**Tarea:** Configura y entrena la red neuronal.\n",
    "\n",
    "**Sugerencias:**\n",
    "- Usa `nn.MSELoss()` como función de pérdida para problemas de regresión\n",
    "- Prueba con diferentes optimizadores como SGD o Adam\n",
    "- Implementa un bucle de entrenamiento que itere sobre los datos en mini-lotes\n",
    "- Monitorea la pérdida durante el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función de pérdida y el optimizador\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Puedes probar con diferentes tasas de aprendizaje\n",
    "\n",
    "# Parámetros de entrenamiento\n",
    "num_epochs = 1000\n",
    "batch_size = 32\n",
    "\n",
    "# Tu código aquí para implementar el bucle de entrenamiento\n",
    "# Recuerda:\n",
    "# 1. Iterar sobre las épocas\n",
    "# 2. Para cada época, iterar sobre los mini-lotes\n",
    "# 3. Calcular la salida del modelo (forward pass)\n",
    "# 4. Calcular la pérdida\n",
    "# 5. Reiniciar los gradientes (optimizer.zero_grad())\n",
    "# 6. Retropropagar la pérdida (loss.backward())\n",
    "# 7. Actualizar los pesos (optimizer.step())\n",
    "# 8. Registrar y mostrar la pérdida\n",
    "\n",
    "# Graficar la curva de aprendizaje\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Tu código aquí\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 4: Evaluación\n",
    "\n",
    "**Tarea:** Evalúa el modelo utilizando el error absoluto medio (MAE) para medir el rendimiento en el conjunto de prueba.\n",
    "\n",
    "**Sugerencias:**\n",
    "- Usa `model.eval()` para cambiar el modelo al modo de evaluación\n",
    "- Usa `with torch.no_grad()` para desactivar el cálculo de gradientes durante la evaluación\n",
    "- Visualiza las predicciones vs. los valores reales en un gráfico de dispersión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Evaluar el modelo\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Tu código aquí para evaluar el modelo en el conjunto de prueba\n",
    "    # y calcular métricas como MSE y MAE\n",
    "\n",
    "# Visualizar predicciones vs valores reales\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Tu código aquí\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación con Fashion-MNIST\n",
    "\n",
    "### Ejercicio 3: Clasificación de Imágenes con Fashion-MNIST\n",
    "\n",
    "En este ejercicio, implementaremos una red neuronal multicapa para clasificar imágenes del dataset Fashion-MNIST, que contiene 70,000 imágenes en escala de grises de 10 categorías diferentes de prendas de vestir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Definir transformaciones\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Cargar los conjuntos de datos de entrenamiento y prueba\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Crear data loaders\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Definir las clases\n",
    "classes = ['Camiseta/Top', 'Pantalón', 'Suéter', 'Vestido', 'Abrigo',\n",
    "           'Sandalia', 'Camisa', 'Zapatilla', 'Bolso', 'Botín']\n",
    "\n",
    "# Visualizar algunas imágenes de ejemplo\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # desnormalizar\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Obtener algunas imágenes aleatorias\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Mostrar imágenes\n",
    "plt.figure(figsize=(10, 4))\n",
    "imshow(torchvision.utils.make_grid(images[:8]))\n",
    "\n",
    "# Imprimir etiquetas\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 2: Definir la Red Neuronal\n",
    "\n",
    "**Tarea:** Define una red neuronal multicapa para clasificación.\n",
    "\n",
    "**Sugerencias:**\n",
    "- Recuerda que las imágenes de Fashion-MNIST son de 28x28 píxeles, por lo que necesitarás aplanarlas a un vector de 784 elementos\n",
    "- Usa varias capas completamente conectadas (`nn.Linear`)\n",
    "- Considera añadir capas de dropout (`nn.Dropout`) para reducir el sobreajuste\n",
    "- La capa de salida debe tener 10 neuronas (una para cada clase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionMNISTNet, self).__init__()\n",
    "        # Tu código aquí para definir la arquitectura de la red\n",
    "        # Recuerda aplanar la imagen y usar múltiples capas\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Tu código aquí para definir el flujo de datos\n",
    "        pass\n",
    "\n",
    "# Crear el modelo\n",
    "model = FashionMNISTNet()\n",
    "print(model)\n",
    "\n",
    "# Definir la función de pérdida y el optimizador\n",
    "# Para problemas de clasificación, CrossEntropyLoss es una buena opción\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Elige un optimizador adecuado\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 3: Entrenamiento\n",
    "\n",
    "**Tarea:** Entrena la red neuronal y monitorea su rendimiento.\n",
    "\n",
    "**Sugerencias:**\n",
    "- Implementa un bucle de entrenamiento similar al del ejercicio anterior\n",
    "- Calcula y registra la precisión (accuracy) además de la pérdida\n",
    "- Evalúa el modelo en el conjunto de prueba después de cada época"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros de entrenamiento\n",
    "num_epochs = 10\n",
    "\n",
    "# Listas para almacenar las métricas\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "# Función para calcular la precisión\n",
    "def calculate_accuracy(model, data_loader, device='cpu'):\n",
    "    # Tu código aquí para calcular la precisión\n",
    "    pass\n",
    "\n",
    "# Tu código aquí para implementar el bucle de entrenamiento\n",
    "# Recuerda calcular y registrar tanto la pérdida como la precisión\n",
    "\n",
    "# Graficar las curvas de aprendizaje\n",
    "plt.figure(figsize=(12, 5))\n",
    "# Tu código aquí para graficar la pérdida y la precisión\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 4: Evaluación y Visualización\n",
    "\n",
    "**Tarea:** Evalúa el modelo entrenado y visualiza sus predicciones.\n",
    "\n",
    "**Sugerencias:**\n",
    "- Calcula la precisión global en el conjunto de prueba\n",
    "- Visualiza algunas predicciones junto con las etiquetas reales\n",
    "- Calcula y visualiza la matriz de confusión para entender mejor los errores del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Tu código aquí para evaluar el modelo y recopilar predicciones\n",
    "\n",
    "# Visualizar algunas predicciones\n",
    "# Tu código aquí\n",
    "\n",
    "# Calcular y visualizar la matriz de confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Tu código aquí para calcular y visualizar la matriz de confusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursos Adicionales\n",
    "\n",
    "### Lecturas Recomendadas\n",
    "\n",
    "1. **Optimizadores en Deep Learning**: Una de las mejores lecturas sobre optimizadores se encuentra en [este blog](https://www.ruder.io/optimizing-gradient-descent/). Es altamente recomendada para entender en profundidad los diferentes algoritmos de optimización.\n",
    "\n",
    "2. **Datasets Personalizados en PyTorch**: Para aprender a crear datasets personalizados en PyTorch, puedes revisar [este notebook](https://github.com/santialferez/mlmae/blob/master/Mouth_cat_detection_colab.ipynb) que explica paso a paso cómo implementar la clase `Dataset` de PyTorch.\n",
    "\n",
    "3. **Documentación Oficial de PyTorch**: Para profundizar en PyTorch, consulta la [documentación oficial](https://pytorch.org/tutorials/) que contiene tutoriales detallados sobre todos los aspectos del framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio Opcional\n",
    "\n",
    "**5. Lectura y Análisis de Implementación Personalizada**\n",
    "\n",
    "Hace unos pocos años se creó [este notebook](https://github.com/santialferez/mlmae/blob/master/Mouth_cat_detection_colab.ipynb) en PyTorch, con el fin de explicar cómo crear un `Dataset` personalizado en PyTorch. \n",
    "\n",
    "**Tarea:**\n",
    "1. Lee el notebook en detalle y ejecútalo en Colab (puede que necesites actualizar alguna parte del código).\n",
    "2. El notebook menciona una de las mejores lecturas que existe sobre optimizadores en [este blog](https://www.ruder.io/optimizing-gradient-descent/). Léela para profundizar tu comprensión sobre los diferentes algoritmos de optimización.\n",
    "3. Reflexiona sobre cómo podrías aplicar estos conocimientos a tus propios proyectos de deep learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
