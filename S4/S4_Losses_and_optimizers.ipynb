{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicación de NNLLLoss y CrossEntropyLoss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)\n",
    "\n",
    "CrossEntropyLoss es ampliamente utilizado en tareas de clasificación donde las salidas son probabilidades que suman uno. Mide la disimilitud entre la distribución de etiquetas verdaderas y las predicciones, penalizando las probabilidades en función de cuán lejos están de la etiqueta real.\n",
    "\n",
    "**Ecuación:**\n",
    "$$ \\text{CrossEntropyLoss} = -\\sum_{c=1}^M y_{o,c} \\log(p_{o,c}) $$\n",
    "\n",
    "Donde:\n",
    "- $ M $ es el número de clases.\n",
    "- $ y_{o,c} $ es un indicador binario (0 o 1) si la etiqueta de clase $ c $ es la clasificación correcta para la observación $ o $.\n",
    "- $ p_{o,c} $ es la probabilidad predicha de que la observación $ o $ pertenezca a la clase $ c $.\n",
    "\n",
    "**Ejemplo:**\n",
    "Supongamos que tenemos un problema de clasificación de 3 clases y la etiqueta verdadera para una instancia es la clase 2, representada como codificada en caliente `[0, 1, 0]`. Si las probabilidades predichas para las clases son `[0.2, 0.7, 0.1]`, el CrossEntropyLoss se calcula como:\n",
    "\n",
    "$$ -\\left(0 \\times \\log(0.2) + 1 \\times \\log(0.7) + 0 \\times \\log(0.1)\\right) = -\\log(0.7) \\approx 0.357 $$\n",
    "\n",
    "**Nota**: PyTorch lo que calcula realmente es $ \\text{CrossEntropyLoss} = -\\sum_{c=1}^M y_{o,c} \\log\\left(\\frac{e^{l_{o,c}}}{\\sum_{j=1}^M e^{l_{o,j}}}\\right)$. Donde $ l_{o,c} $ son los logits (puntuaciones sin procesar) para la clase $ c $ de la observación $o$. Es decir que, PyTorch aplica internamente la función softmax a los logits antes de calcular el logaritmo de las probabilidades, lo cual es parte integral del cálculo de CrossEntropyLoss.\n",
    "\n",
    "\n",
    "### [NLLLoss](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss) (Negative Log Likelihood Loss)\n",
    "\n",
    "NLLLoss se utiliza cuando las salidas del modelo son logaritmos de probabilidades. Esta función de pérdida es más simple ya que utiliza directamente los logaritmos de probabilidades proporcionados por el modelo, enfocándose específicamente en el logaritmo de la probabilidad de la clase verdadera.\n",
    "\n",
    "**Ecuación:**\n",
    "$$ \\text{NLLLoss} = -\\text{LP}_{\\text{claseVerdad}} $$\n",
    "\n",
    "Donde:\n",
    "- $ \\text{LP}_{\\text{claseVerdad}} $ es el logaritmo de la probabilidad de la clase verdadera según lo proporciona la salida del modelo.\n",
    "\n",
    "**Ejemplo:**\n",
    "Continuando con la configuración anterior, si el modelo produce logaritmos de probabilidades para las clases como `[-1.61, -0.3567, -2.30]` (correspondiendo a las probabilidades `[0.2, 0.7, 0.1]`), y la clase verdadera es la segunda, el NLLLoss es:\n",
    "\n",
    "$$ \\text{NLLLoss} = -(-0.3567) = 0.3567 $$\n",
    "\n",
    "### Resumen\n",
    "\n",
    "- **CrossEntropyLoss** se utiliza cuando las salidas del modelo son puntuaciones brutas (logits) o probabilidades. Aplica una softmax para convertir logits en probabilidades, seguido de calcular el logaritmo de estas probabilidades, y finalmente calcula la pérdida de logaritmo negativo.\n",
    "- **NLLLoss** se utiliza cuando las salidas del modelo ya están en forma de logaritmos de probabilidades. Calcula directamente el negativo del logaritmo de la probabilidad de la clase correcta.\n",
    "\n",
    "Estas funciones de pérdida guían al modelo durante el entrenamiento penalizando las predicciones basadas en cuánto se desvían de las etiquetas reales, ayudando así en el aprendizaje de las correspondencias correctas de entradas a salidas.\n",
    "\n",
    "| Nombre de la Pérdida                  | Cuándo se usa                         | Cómo son los Inputs                          |\n",
    "|---------------------------------------|---------------------------------------|----------------------------------------------|\n",
    "| CrossEntropyLoss                      | Clasificación multiclase              | Logits (puntuaciones sin procesar)           |\n",
    "| NLLLoss                               | Clasificación multiclase con probabilidades logarítmicas | Logaritmos de probabilidades (después de LogSoftmax) |\n",
    "| BCELoss          | Clasificación binaria                 | Probabilidades (después de una función sigmoide) |\n",
    "| BCEWithLogitsLoss      | Clasificación binaria                 | Logits (puntuaciones sin procesar)           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicación del Optimizador Adam\n",
    "\n",
    "#### Introducción a SGD y Momentum\n",
    "\n",
    "Para entender Adam, primero es útil comprender el optimizador de Gradiente Descendente Estocástico (SGD) y el concepto de momentum. SGD es un método para optimizar una función objetivo, típicamente una función de pérdida en aprendizaje automático, que se actualiza en base a los gradientes de la función con respecto a los parámetros del modelo. La actualización básica de SGD se puede expresar como:\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - \\rho \\nabla_\\theta J(\\theta_t)$$\n",
    "\n",
    "Donde:\n",
    "- $\\theta$ son los parámetros del modelo.\n",
    "- $\\rho$ es la tasa de aprendizaje.\n",
    "- $J$ es la función de pérdida.\n",
    "- $\\nabla_\\theta J(\\theta_t)$ es el gradiente de la función de pérdida respecto a $\\theta$ en el tiempo $t$.\n",
    "\n",
    "**Momentum** es una técnica para acelerar SGD en la dirección correcta y suavizar las actualizaciones. Se añade un término de \"velocidad\" $v_t$ que incorpora gradientes pasados:\n",
    "\n",
    "$$v_{t+1} = \\mu v_t + \\rho \\nabla_\\theta J(\\theta_t)$$\n",
    "$$\\theta_{t+1} = \\theta_t - v_{t+1}$$\n",
    "\n",
    "Donde $\\mu$ (típicamente alrededor de 0.9) es el factor de momentum que determina la contribución de gradientes pasados.\n",
    "\n",
    "#### Adam: Adaptive Moment Estimation\n",
    "\n",
    "Adam, que significa \"Adaptive Moment Estimation\", combina las ideas de momentum y escalado adaptativo de los gradientes por segundo momento. Adam mantiene estimaciones del primer momento (el promedio de los gradientes, similar a momentum) y del segundo momento (el promedio de los cuadrados de los gradientes) de los gradientes.\n",
    "\n",
    "Las ecuaciones de Adam son:\n",
    "\n",
    "1. **Calcular los gradientes**:\n",
    "   $$g_t = \\nabla_\\theta J(\\theta_t)$$\n",
    "\n",
    "2. **Actualizar los momentos estimados**:\n",
    "   $$m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t$$\n",
    "   $$v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2$$\n",
    "\n",
    "   Donde:\n",
    "   - $m_t$ es el primer momento (media de los gradientes).\n",
    "   - $v_t$ es el segundo momento (media de los cuadrados de los gradientes).\n",
    "   - $\\beta_1$ y $\\beta_2$ son factores de decaimiento exponencial para los momentos estimados (típicamente 0.9 y 0.999).\n",
    "\n",
    "3. **Corrección de sesgo**:\n",
    "   $$\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}$$\n",
    "   $$\\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}$$\n",
    "\n",
    "4. **Actualizar los parámetros**:\n",
    "   $$\\theta_{t+1} = \\theta_t - \\frac{\\rho \\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}$$\n",
    "\n",
    "   Donde $\\epsilon$ es un pequeño número para evitar la división por cero (típicamente $10^{-8}$).\n",
    "\n",
    "#### AdamW: Adam with Weight Decay\n",
    "\n",
    "AdamW es una variante de Adam que desacopla el término de decaimiento de peso de la actualización de los parámetros. En Adam, el decaimiento de peso se aplica junto con la actualización de los parámetros, lo que puede llevar a una implementación incorrecta del decaimiento de peso. AdamW modifica la actualización de Adam para aplicar correctamente el decaimiento de peso:\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - \\rho \\left(\\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon} + \\lambda \\theta_t\\right)$$\n",
    "\n",
    "Donde $\\lambda$ es el coeficiente de decaimiento de peso.\n",
    "\n",
    "Adam y AdamW son ampliamente utilizados en la práctica debido a su robustez y buen desempeño en una variedad de problemas de optimización en aprendizaje automático. Estos optimizadores son especialmente útiles cuando se trabaja con grandes conjuntos de datos y/o modelos de alta dimensionalidad, donde los métodos tradicionales como SGD puro pueden ser menos eficientes o converger lentamente.\n",
    "\n",
    "En resumen, Adam y AdamW proporcionan mecanismos avanzados para ajustar los parámetros del modelo de manera más efectiva, adaptándose a las propiedades del gradiente y del problema específico, lo que a menudo resulta en una convergencia más rápida y estable en comparación con el uso de SGD con o sin momentum.\n",
    "\n",
    "\n",
    "Referencia\n",
    "\n",
    "https://www.ruder.io/optimizing-gradient-descent/"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
